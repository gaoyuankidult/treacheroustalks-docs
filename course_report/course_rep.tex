\documentclass[11pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[numbers]{natbib}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{datetime}
\usepackage{color}

\newcommand{\hi}[1]{{\color{red}\tiny \em #1\/}\\}
\newcommand{\todo}[1]{\footnote{{\color{red} {\bf TODO:} #1}}}

\begin{document}
\title{Course Report \\
  ``Treacherous Talks''}
\date{\today\ @ \currenttime}
\author{Dilshod Aliev, Jan Daniel Bothma, Stephan Brandauer,\\
 Andre Hilsendeger, Rahim Kadkhodamohammadi, Xinze Lin,\\
Tiina Loukusa, Erik Timan, Sukumar Yethadka}
\maketitle
\tableofcontents

\abstract{
Treacherous Talks is an implementation of a board game (``Diplomacy'') as a web
service.

We developed the service completely in erlang while spending lots of time on
optimizing performance and scalability. The project was mostly self organized
by an international team of 9 students and developed using Scrum.
}
\chapter{Introduction}
Diplomacy is a board game, invented in the 1950s where the goal is to try to
conquer Europe just before WW I. You come close to this goal by talking to the
other players --- by diplomacy --- and making them your allies. And you achieve
it by attack them when they do not expect it.

The game is and was commonly played over distance --- starting with playing by
mail, then email and nowadays over pretty web pages with full-blown map
visualization.

The requirements we were faced with asked for implementation of Diplomacy as a
web service while providing several interfaces to this service. Scalability and
Failure Tolerance were of high priority. \\
Even though a board game is a fun thing to implement, we do think that the most
interesting part of our project is the scalability- and fault tolerance-
engineering.
\todo{Make unique - product rep uses same introduction}

\chapter{Resources}
\section{Team}
Since we decided to arrange our workplaces in a triangular shape
\todo{picture of office}, we gave our team the name ``Team Bermuda Triangle''.
This is only one example for how quickly we had formed a well functioning
team. \\
Even though we differed in nationalities as well as ages, we had no
troubles whatsoever to start working together from the start.\\
\\
The team members were: \\

\newcommand{\flag}[1]{\includegraphics[height=10pt,width=15pt]{flags/#1}}

\begin{tabular}{lcrl}
Dilshod Aliev & Tajikistan & \flag{tajikistan.png} \\ \hline
Jan Daniel Bothma & South Africa & \flag{south_africa.png} \\ \hline
Stephan Brandauer & Austria & \flag{austria.jpg} \\ \hline
Andre Hilsendeger & Germany & \flag{germany.jpg} \\ \hline
Rahim Kadkhodamohammadi & Iran & \flag{iran.png} \\ \hline
Xinze Lin & China & \flag{china.png} \\ \hline
Tiina Loukusa & Sweden & \flag{sweden.png} \\ \hline
Erik Timan & Sweden & \flag{sweden.png} \\ \hline
Sukumar Yethadka & India & \flag{india.png}
\end{tabular}\\
\\
A list of the team members would not be complete without mentioning
Karl Marklund, the TA overlooking our project.
Karl has been a great help with all kinds of problems, from getting more
hardware to giving us tips and feedback. Thank you!

\section{Equipment}
We had nine development PCs (HP made) supplied from the university, as
well as three more PCs as servers (git, redmine, gerrit, buildbot),
a meeting/presentation workstation, a fault tolerance testing PC,
and one PC as load generator for load testing. \\
Our office room was equipped with several white boards that proved to be
very valuable, especially in times where much design and architecture was done.
\section{Tools}
\subsection{Issue Tracking}
All projects need a system for tracking issues and planning. We opted to use
one of the more popular open-source solutions called Redmine, a web-based issue
tracker and project management system. Redmine was useful to us for several
reasons:
\begin{itemize}
\item Built-in wiki \\
  We used the wiki as a basis for high level documentation of things such as our
  architecture and design, guidelines, scrum process details, test flow results,
  our data model and many other things.
\item Scrum plugin \\
  Redmine has a plugin system and we used the Backlogs plugin heavily. It is a
  plugin designed to help teams using scrum. It was very valuable since it
  quickly replaced the post-it based scrum board solution while providing the
  same visual overview. The scrum master had to spend no time on keeping our
  issue tracker and physical scrum board consistent any more.
\item Forum \\
  We used it for discussions during the initial sprints.
\item Version control integration \\
  We used the version control integration mostly for connecting tickets in
  Redmine to the associated commits in our git repository.
\end{itemize}
\subsection{Version Control}
Perhaps even more vital to a software development project is a good version
control system. There are several out there, but the most common open-source
ones are Subversion and git. They are fundamentally different and we chose git
since it has very good tool support and handles branching and merging very well.

Another plus for git is Github, an online repository hosting service. Most
open-source software written in Erlang (including Erlang/OTP itself) is hosted
on Github. This makes the process of making modifications to upstream code a lot
easier since it is trivial to fork (create your own hosted copy of another
repository) repositories on Github.
\subsection{Continuous Integration}
Continuous Integration (CI) is the process of building, testing and integrating
software in a continuous fashion. In practice, you use a special software that
checks out a copy of your source code tree from a version control repository and
runs various commands manipulating that source tree, returning some result to
the developers.

Initially we installed Jenkins to do this since it is widely used. We tried to
integrate it with our code review system, but the plugins for doing that was
very unstable and crashed often. We set out to find another system we could use
and found Buildbot. Buildbot is a bit different from most other CI servers since
it is more like a framework than a finished product. You configure Buildbot by
writing a Python program describing what it should do.

When we got Buildbot running and working integration with the code review
system, the team almost started treating it as our tenth team member. It proved
to be valuable to have this since it allowed us to avoid integration problems
early on. Our combination of Buildbot and the code review system made it
impossible to merge anything to our master branch without passing all tests.
\subsection{Code Reviews}
It is well known that it can be very useful to review code when developing
software for a number of reasons. One is that it often catches bugs that can be
hard to find with regular testing, another is that it allows other developers to
get acquainted with your own code. While many development projects uses code
review in some fashion or another, we wanted to try a more formal approach to
see if it could help us improve our code quality.

We quickly settled on using the code review system Gerrit. It was by far the
easiest code review system to setup for git. The idea was to combine continuous
integration with the code review system to ensure that developers pay attention
to the results from Buildbot and that the master branch always is buildable and
releasable. It works like this:

When a developer pushes a change to the repository, she can not push to the
master branch directly but only to a new branch in Gerrit. Gerrit then publishes
this change in a pretty web interface for everyone to see {\bf and} tells
Buildbot to run the tests with that change. Now the other developers can review
that change by either looking at the changed files in the web interface or by
pulling them to their local repositories and try them out. If a developer finds
a problem, she can insert comments directly in the web interface for the author
to see and give a negative review in order to prevent merging of the change.

When the author has reacted to those comments, updated her change and the
reviewer is finally happy, the reviewer can give the change a positive rating
and submit the change, merging it to the master branch.

We configured our system so that if Buildbot {\bf and} at least one reviewer
agree that the change can be merged, Gerrit will do so. This process proved to
be incredibly safe, many bugs were found very early and our build broke (could
not compile the master branch) only once during the whole project. Some team
members actually started to use this system to get early feedback on unfinished
code and this worked out pretty well. Even though Gerrit+Buildbot is not easy to
set up, we think that future teams could profit a lot by using something
similar. We really do think that this workflow has improved our product and that
the invested time payed off.

We also use this system for more than code. In fact, while this report is
written, it is being code reviewed as well in the same manner.
\subsection{Building}
Build tools are important, especially since bad tools tend to cause frustration
among developers. We started using the Erlang build tool Rebar from day one in
our project since it is the de-facto build tool in the Erlang community. Rebar
can do quite a lot of things besides just compiling code. It also helps us run
tests and create releases.

We spent many hours integrating code from external parties into our system, such
as the server parts of our frontends. The majority of the external projects was
buildable with Rebar, but not the major ones such as ejabberd and exmpp. They
use plain Makefiles and are not releasable since they are not proper OTP
applications. To our great pleasure we learned at the Erlang User Conference
that there are forked versions of these projects that are OTP compliant and can
be built with Rebar. We switched to these forked ones late in our project, and
it simplified and sped up our build system a lot.

One thing we did not fully understand in the beginning was the relationship
between applications and releases. We thought that having a separate release for
our backend and each of our frontends was a good idea. While this is a fully
valid way to do things, it made life more complex when we tried to deploy and
configure a whole cluster. In retrospective, we should have kept all our
applications in one release and then dynamically start the ones we want to be
running on a specific node. That would have saved us some time and gray hair.
\subsection{Unit and Integration Testing}
There are several test frameworks for Erlang, but we used the standard EUnit
framework for testing for pretty much everything. We did so without really
considering CommonTest, so we do not know whether that choice was optimal or
not. EUnit worked okay for us but we had some problems with it.

One problem is that EUnit assumes an automatic timeout of 5 seconds for all
tests. If a test takes a long time to run (not uncommon in our system - we're
talking to a database), this timeout can become really annoying since some tests
takes longer under high load. Often tests would fail on Buildbot that did not
fail on our local machines. This was mostly because of the Buildbot machine
running several builds in parallel, creating a high load on that system. To make
matters worse, EUnit does not seem to have one central switch to change that
default value but only lets you change the value for single tests.

Another problem with EUnit is that tests often gets highly nested with lots of
anonymous functions being passed around. This makes it confusing to read test
code and sometimes hard to find the real problem behind a failing test.

We also had integration tests for our frontends. Each frontend had a basic
integration test checking that a user could log in and maybe do a few
operations. We used Selenium for testing the web frontend, and it turned out to
work okay-ish even though it was hard to write good tests for our
Javascript-heavy web frontend.
\subsection{Load Testing}
\todo{Write something about Basho Bench}
\chapter{Project Methodology and Organization}

\section{The Customer}
Our customer was Jan Henry Nyström from Erlang Solutions. Henry's job according to
Scrum was to prioritize the tasks at hand and be at the planning meeting.
What Henry did instead was to act more like a teacher which led to confusion on
our side at the beginning of the project. Once we got accustomed to that,
we were able to work very efficiently for and with him.
Henry's experience in developing erlang systems was extremely useful and we hope
that he learned a little bit through this project as well since some of our
tools were not known to him (in practice) before.
\section{Erlang User Conference!}
We were invited to present our project in poster form at the
Erlang User Conference in Stockholm. The attendance was free of charge for us
thanks to Erlang Solutions. \\
In Stockholm many people asked about the project, most questions were on a high
level, though. We did not get direct feedback that changed the project after the
EUC but the talks there were quite relevent to our project and therefore a big
help. \\
It was as well a very fortunate place for us to be as some companies that were
there are actively trying to hire young developers with erlang experience.
\section{Scrum}
For managing our project we used Scrum as in~\cite{kniberg}.
We tried hard to start up a well functioning software process and believe that
we succeeded. Our flavour of Scrum looked as follows: \\ \\
\begin{tabular}{cc}
  when & what \\ \hline
  daily & standup meeting\\
  weekly & fika \\
  beginning of sprint & planning \\
  end of sprint & demo \\
  end of sprint & retrospective \\
\end{tabular}

\subsection{Standup Meeting}
The standup meeting was strictly limited in time: to 15 minutes (although we
rarely reached 15 minutes). The standup meeting was held at 9:00 sharp every day
except for some planning days. In the standup meeting, everyone was giving a
short overview of his/her last day and of the plan for this day: ``Yesterday, I
did \ldots, I had problems with \ldots; today, I am going to \ldots''.
The positive effects of this are quite subtle and it might be easy to think that
such a meeting is not really necessary, especially when everyone is in the same
room:\\
\begin{itemize}
\item it encourages people to talk about their problems!
  Problems are not something one should hide. Many easy solutions for seemingly
  big problems came out of this procedure.
\item people maintain an overview of the project state even in the parts of the
  project they have not touched in ages.
\item since everything is announced before-hand,
  (``today, I am going to \ldots''), bad decisions can be caught, the rule to
  always work on the most important item is enforced and so on.
\item the standup meeting is an ideal opportunity for the scrum master to team
  up people who don't really know what they should work on.
\end{itemize}
\subsection{Fika}
The swedish tradition of having Fika was something that has been practiced by
several teams on this course before us and we unanimously voted to have weekly
Fika, too. Every monday, one member of the team would bring cake or pastry and
we would eat together and have coffee or tea. This was a delicious way to get to
know the team better. \\
In order to make people punctual (or: in order to have more Fika!), we decided
that each time someone is late for the standup meeting, that person has to
bring one extra Fika (or ``punishment Fika'', as we called it).
JD was the clear winner!
\subsection{Planning}
Planning was our least favourite task but nonetheless a very important one.
Our typical planning day looked as follows:
\begin{itemize}
\item 9.00--9.45: {\bf estimation of available person-days,
  prioritizing of backlog stories}\\
  Who will be missing? What else is coming up (presentations, EUC, etc.)?
  What do we want to accomplish in this sprint?
  What is most important to the customer? The customer was missing that task
  often, so we had to guess what Henry would think.
\item 10.00--10.45: {\bf breaking down stories into tasks}\\
  Splitting the big stories into smaller tasks that ideally do not depend on
  each other --- but that was often easier said than done.
  Also: setting ``definitions of done'' (DoDs).
\item 11.00--14.30: {\bf estimating stories}\\
  (with breaks!)
  Guessing how long each story would take with the additional information from
  task breakdown and DoDs.
\item 14.30--15.00: {\bf committing to sprint}\\
  Taking the prioritized, estimated stories and committing to as many as the
  available person days allowed.
\item 15.00--16.00: FIKA
\end{itemize}

\subsection{Demo}
The demo was held at the end of each sprint. Since in Scrum to try to produce
something that is potentially shippable in each sprint, the demo is there to
ensure that. We invited teaching staff and customer to the demos and showed them
what we did in the last weeks. The demo was always a nice ending of a sprint for
us, because it is in a quite relaxed atmosphere and we were more proud of our
product than worried.

\subsection{Retrospectives}
The retrospective was the absolutely last thing of a sprint --- in a team
meeting we talked about what we liked about the last sprint, what we disliked,
and what we would like to do differently in the next sprint. \\
It was very important to focus on getting negative feedback at first, people
were generally reluctant to give it because they did not want to seem rude or
be critizised themselves. This is, why we had the rule in the first one or two
retrospectives, that everyone {\em has\/} to come up with at least one of each
category. This worked quite well and in the end, even negative feedback was
coming quite easily, although personal criticism was very rare if occuring at
all. \\
After we collected feedback (we collected it in form of post-its on a
whiteboard), we ``dot-voted'' --- everyone gets three or four votes and can
distribute them in the form of a dot over the negative items on the board.
Giving multiple dots to one item is allowed. We took the three items with the
most points and tried to fix them in the course of the next sprint.

\section{Quality Management}
\subsection*{Coding Conventions}
Our coding conventions were agreed on in sprint 1 and we enforced them through
code reviews. Obviously some things were overlooked but the code quality
doubtlessly profited a lot from that practice.
The coding conventions governed coding style (eg.\ max-80-char-lines, no
trailing white space) as well as erlang specifics (eg.\ how to use {\tt catch}).
\subsection*{Reviews}
Reviews were done mostly by whoever had time. A good time for a dev to do
reviews was while buildbot was testing her newest change. Sometimes, though,
reviews were requested or even traded: ``I'll review your change, if you'll
review mine''. \\
At first it was annoying to have to wait for some time before a change was
actually merged. After a while, though, we got used to the fact that nothing is
merged immediately and continued to work on the next task while our old one was
awaiting review.

Reviews were generally well meaning but that does not mean that we accepted bad
code quality. People tended to look away when a function was not documented here
and there but there still were plenty of negative reviews.

\subsection*{Testing}
We took testing very seriously and the considerable time we invested payed off.
A counting on december 7$^{th}$, 2011 showed that 47\% of code lines were testing
code. This big suite of tests made it incredibly easy to verify that a change
didn't break anything. If developers are secured by a solid test suite, it is
also easier to start working on code that is not so well known because one
always has a regression test suite that immediately highlights errors.

\section{Timeline}
\subsection*{Sprint 1 --- Sprint Goal: ``Getting Ready to Code''}
\subsubsection{Servers}
We set up a git- and a redmine-server, buildbot was not
a task in this sprint. We started off with JD as scrum master and Stephan as
spokesperson. Scrum was done on a whiteboard with post-its.
As we all were new to the process, it took us a little while to figure out how
to act.
\subsubsection{Surveys}
We tried out some tools/libraries and evaluated how they would fit
our project. The end result of that process was (see Appendix B for details): \\
\\
\begin{tabular}{r|l}
Ubuntu 11.04 & operating system \\
Git          & version control  \\
Gerrit       & code reviews     \\
Riak         & database         \\
Nitrogen     & webframework     \\
Ejabberd     & XMPP server      \\
gen\_smtp    & emailing         \\
Buildbot     & continuous integration server
\end{tabular}
\subsubsection{Git-School}
Since almost everyone was new to git, Erik talked to some slides about git and
we all did a couple assignments with git afterwards.
The other team was invited as well.
\subsubsection{Requirements}
We worked on the requirements a lot: we clarified them, prioritized them and had
our customer sign off the outcome of this process. It was crucial, that the
customer was happy with the result since we knew that this result would shape
the rest of our project.
\subsubsection{Preliminary Architecture}
We opted for a reviewed architecture process and would highly recommend it to
future teams as well: \\
A group of people was working on an architecture proposal for a couple of days.
Then one person of that group walked a review~group through the result. The
review~group then took the requirements and tried to run them through the
architecture. This proved to be very effective but of course work-intensive. \\
Given the importance of the architecture, the amount of work was acceptable.

\subsection*{Sprint 2 --- Sprint Goal: ``CRU Users''}
\subsubsection{Continuous Integration}
We set up buildbot. Making our build process compatible with buildbot was a lot
of work and maintaining the build process was a task in all future sprints.

Even though Continuous Integration was a lot of work to get up and running, the
productivity bonus it gave us more than made up for it in the long run.

\subsubsection{Testing Competency}
Some team members had not much or no real experience in writing tests, no one
had experience in writing tests in erlang. Therefore we chose to hold a
{\em testing school\/} much like sprint 1's git school.

\subsubsection{Load Test Riak}
Since our first design drafts showed that riak would be very central to our
performance, we decided that a quick load test of riak was in order just to
ensure that it `works'. The results where not extremely surprising and therefore
we continued to rely on riak.

\subsubsection{Interfaces}
We laid the foundations for our interfaces: http (websockets), xmpp, smtp.
The DoD was to have them answer a `ping' with a `pong' or anything comparable.

\subsubsection{Registering, Login, \ldots}
We gave users the possibility to register on our system, to login and to update
their user information. First connections from the interfaces down to the
database were made!

\subsubsection{Problems!}
After sprint 1 which went very well, we were a bit too careless in sprint 2's
planning, especially the estimation - we underestimated the integration of
all user interfaces into the system A LOT.
For this reason, we committed to too many stories and were not able to complete
them by the end of sprint 2. \\
We vowed to not make this mistake again.

\subsection*{Sprint 3 --- Sprint Goal: ``Play a Basic Game''}
From this sprint on, JD resigned as our scrum master --- but he had warned us
from the beginning of the project. Andre replaced him with the beginning of
sprint~3.

\subsubsection{Erlang User Conference '11}

Attending the EUC'11 was on our agenda. For that we had to make a
poster, which had to pass several stages of reviews. This proved to be very
time~consuming.
\subsubsection{Refactor UIs}
Since the input channels (http, xmpp, smtp) had been developed in parallel in
the last sprint, they were full of code duplication. We changed that and as well
extended them greatly.
\subsubsection{Game Application}
Since we wanted to be able to play games, we worked hard on the Game
Application. This ranged from setting up games as user (stored in the DB),
changing their phases according to a timer to implementing the game rules.

\subsection*{Sprint 4 --- Sprint Goal: ``Find the Limits of Real Games''}
\subsubsection{Load Testing}
We applied high load to our system and measured where the limits are (and how
they look like). The load tests showed us severe but easily fixable bugs that
we had in our system; we would not have found them otherwise. The scalability
was quite satisfactory for a first try, the raw performance however was
degrading over time until after $\approx$1h the backends crashed. We fixed this
easily by a riak-reconfiguration but did not figure out where the problem came
from exactly.

\subsubsection{Messaging}
The messaging-part explains the word ``Real'' in the sprint goal since one
cannot play a good diplomacy game without communicating.\\
The messaging system needed to support offline messages (when a user receives a
message while she is offline, the message should be delivered upon login).

\subsubsection{Fault tolerance testing}
We needed a (semi-) automatic way of testing fault tolerance, since distributed
functionality like that is not possible to test with eunit and can be quite tedious.
So we installed some VM containers on one of our servers, that could be used to run
multiple instances of the system on one machine.
The goal for this story was to provide the testing framework, not the fault tolerance itself,
as this would have been too much.
Our system- and cluster managers are a byproduct of this.
They simplify the setup and start of a cluster by a great deal.

\subsection*{Sprint 5 --- Play game \& Operator is watching}
\subsubsection{Review 2}
Each team had to present their results, including a short demo.
Both teams, the teachers and the customers were present at those presentations.
Additionally some reviewers from the university and other master students were invited.

This was, like the EUC poster, very time consuming.
Since we did not just prepare the demo and the presentation, but we also had a test run,
where Henry Nyström and the teachers were present to give us feedback on the presentation.

We kept it quite non-technical, so that the end presentation could be mostly the same.

\subsubsection{Tune performance}
After load testing in Sprint 4 we discovered that the performance of our system was degrading over time.
The DoD for this story was quite vaguely, as you are never done tuning - and it's just fun!
So we decided to solve the degradation and if there is time left to tune performance,
but not to spend more than 20 man days on that story.

Our riak storage backend was eleveldb, because it is the only one supporting secondary indices.
The assumption was that eleveldb, was responsible for the degradation.
The reason for that assumption was that riak in general does not show such a degradation pattern,
and the default and well-tested storage backend is bitcask.
After replacing all uses of riak's secondary indices with riak search we could switch our backend back to bitcask.
This solved the degradation problem.

Further performance tuning involved adapting the riak write parameters.
Reducing these for the non-crucial writes, like message logging, was a simple optimization.

The last change regarding the performance was regarding another not so well-tested riak feature.
On the \#riak IRC room on irc.freenode.net we have been advised to trying it without riak search.
So we tried to remove it from as many places as possible, and use riak key filtering instead.
Load tests showed this was indeed an improvement in performance.

Worth mentioning about the continuous load tests is that we discovered a drastic performance drop
due to some code changes.
After a little while we could even tell which commit was responsible and why.
As it turns out it once again increased the use of riak search.

\subsubsection{Handle loss of servers}
We implemented the fault tolerance in the fifth sprint after providing the testing framework for it in the previous one.
This was achieved by our necromancer module.
Its responsibility was to watch nodes and react once a node goes down.
The nodes watched each other in circular manner, so that each would be watched by one other node.
Processes with state would simply write important data to the database,
and another node could then resurrect it with that data.

\subsubsection{Operator/Moderator functionality}
Many of our requirements were finished by sprint 5 and the majority of the backlog consisted of
operator/moderator functionality.
So we introduced these user roles and implemented an access control list together with some
functionality requiring privileged access, like inspecting servers and games or blacklisting users.

\subsubsection{Graphical map}
A rather small, but to us very important, feature of that sprint was the graphical map for the web interface.
The game was not really playable with just the textual representation of the map.
We decided to do this only for the web interface, since the other interface are purely text based anyway,
and this was a good task for html5 canvas.

\subsection*{Sprint 6}
The last sprint was very short and was just about finishing up - we did not even have a real planning meeting.
We wrote all required reports (including this one), published our project on github,
and fixed some bugs.
We did not introduce any new features whatsoever.

\chapter{Conclusion}
\section*{To Future Students}
\begin{itemize}
\item  Investing in code quality pays off. Do never, ever, say things like:
``commit this now, we can make it pretty later''. Because you won't!
Do it now or never.
\item Think `product': everything you do is in order to make the product better.
You write high quality code because it makes you more productive, not because
it's cast in stone.
\item Make everyone understand what you are talking about and take your time to
do that.
\item Create an environment where it's ok not to know something so that people
ask instead of trying to cover their problems. Help each other out where you
can.
\item Planning is boring, but still: take your time to do it! It is incredibly
motivating to see that a sprint goal was met after three weeks of hard work.
\item Work transparent: let everyone know what you are doing and why. This way,
you get a lot more valuable feedback and no one can tell you later that what you
did was wrong --- because they knew what you did.
\item Apply Scrum completely. Don't feel bad for saying ``no'' to TA/customer if
you are running out of time and you didn't commit to something.
\item Document early, document often. While this is not the most interesting aspect
of coding, it definitely pays. Invest in your project's future by adding documentation.
\item Automate as much as possible. It always saves time in the long run.
\item Testing is your best friend!
      It saved us several times and makes people less reluctant to refactor
      or change other people's code.
      You can never have enough tests!
      $\sim 50\%$ of our code base was test code and yet we had bugs.
\item Do code reviews, they catch mistakes early and improve code quality.
      It is also one of the best ways to know parts of the system you are
      currently not working on.
\item Talk! Everyone is in the same room, often it's easier to just walk two
      meters, than having a conversation in a forum or the like -
      just don't talk too loud and disturb others!
\item Do Fika! Because it's delicious!
\end{itemize}
\section*{To Teachers/TA}
\begin{itemize}
\item We enjoy your visits and feedback!
\item It is great that you give the teams so much freedom
\item The organisation of the course went very well, you were always helpful
\item A little less report writing / poster making / presentation holding would
  make the product better and the course more fun
\item Talks from industry experts would be very much appreciated
\item English keyboards please!
\end{itemize}


\section*{To wrap it up...}
This was a very fun, exciting and challenging course. We have gained new
knowledge in many areas, and something that was new to us all was the
language Erlang and the project methodology Scrum, we also learned to
use new tools and the importance of testing.\\

In a team like this, with students from different backgrounds in many regards,
from cultural to academical, it is important to respect each other and be humble.
We really benefited from learning to know each other better through fika and
changing who we were working with on different tasks. We didn't enforce
pair programming, but those who felt more comfortable doing that had the
possibility to do it. In our working agreements we recommended team members to
eat lunch in the lunchroom, so we could have a casual chat.\\

Although, it has not been a breeze all the time. The project introduced 
challenges in many regards, as there would be in any project.
But we had basically the same experience with Erlang, and we were more or less
on the same level in regards to that. Tools like git and gerrit were something
new to parts of the team, so there was a learning curve to many things. But in
the end, we all have something new to put in our bag of knowledge and experience.
\appendix

\chapter{Team Statements}
\hi{ (required)

Each group member explains his/her own contributions to the project, maybe half a page each. Make sure that all members agree on these descriptions.}
\section{Dilshod Aliev}
\section{Jan Daniel Bothma}
\section{Stephan Brandauer}
I was the spokesperson of the team from the beginning. As spokesperson,
I saw it as my job to shield the team from distractions as much as possible.

In the beginning, I was doing the survey on zotonic which looked great but too
big for us. Then, I also was part of the architecture team for the initial
draft.

My main topic in sprint 2 was riak. I set up a cluster and was working with the
first benchmark of riak, together with mostly Sukumar.
I committed the initial version of our DB-wrapper module as well.

In sprint 3, I was working on one task only: the rule engine, our implementation
of the rules. During that sprint, I got a lot done but also lost a lot of
overview over the project since I was working on one task, alone.

Sprint 4 started with the generation of test data for the load tests. After
this, my main contribution was necromancer, our fail-safety module as well as
integration of {\tt necromancer} in the system (Tiina and JD did the
implementation of game-restarting).

Sprint 5 had me mostly covered preparing for the presentation of Review~2.
The feedback was quite good, but in my opinion we were forced to spend far too
much time on tasks that do not contribute to the product (I estimate that the
presentation preparation took roughly 3 person weeks).

\section{Andre Hilsendeger}
In the first sprint I was looking into Erlang Web as part of the tools-/library survey.
It turned out to be too basic and we did not use it.
Additionally I was part of the team that created the initial architecture draft.

As expected the initial draft of the architecture was not enough and needed more specifics.
In the second sprint I was once again part of the architecture/design team.
We defined in more detail what the processes are and how they are supervised.
As part of our testing school I also took a look into meck, and gave the team a short introduction
on how to use it.
Since by design most of our backend apps had a similar structure I created a template for those
and created the initial user management app.

From the third sprint on I have been the scrum master.
We noticed quite some code duplications and similarities between our frontends,
so I refactored the logic away from the SMTP and XMPP frontends into the controller.
Due to our database-drive design in combination with riak as our storage backend
we had to figure out how to maintain consistency.
We identified the problems and tried to solve them, adapting the controller to have a
session process for every user was part of that.

During the fourth sprint I implemented the event pushing to online users in the controller,
so that other apps, like the message-app, could push messages to online users.
After that I started my biggest and longest task, load testing.
A big part of that was to automatically setup multiple machines and run load test on them,
while Sukumar and Tiina wrote the actual load tests.

The results from the load test were not very satisfactory, so my task in the fifth, and last real,
sprint was to improve the performance.
For that Rahim and I replaced secondary indices with riak search, so that we could switch back to the bitcask storage backend.
But as it turned out riak search had serious performance problems with often updated data.
So I replaces riak search by key filtering for parts of the system that did not really need the search feature,
like messaging.

\section{Rahim Kadkhodamohammadi}
In the beginning, I was doing some review on Erlang tools for SMTP and XMPP. 
In this sprint Lin and me listed Erlang tools for SMTP and XMPP. I did some experiments with Mnesia database as well.
 
In the second sprint, I continued to do some experiments with ejabberd, 
the only Erlang based XMPP server. I designed and developed an ejabberd component 
that is able to exchange messages with users. Since EXMPP is the 
only Erlang based XMPP client and we need integration tests, I developed the first 
draft of an application with EXMPP to do integration tests through the IM client. 
I was also part of the architecture team.

Sprint 3 was the sprint where we provided functionalities that allow users to play games. 
During this sprint I mainly worked on the command parser, the controller and the game application. 
I could say that it was a great sprint that I worked on most part of the system. 

In sprint 4, I created our first draft of the message application which provides functionality 
to send messages between users. Then I added the ACL (access control list) to our controller. 
I also extended our web frontend to show some system stats to 
operators and provide functionality to add/remove moderators.

In sprint 5, I was part of the presentation team. I was responsible 
to prepare a demo to show during the presentation. I spent some time to
 prepare the demo and fix some bugs which I encountered when played with our system.
 I also extended our game and message applications to support black-listed users.
 
\section{Xinze Lin}
In the first sprint, I was surveying and experimenting Erlang based SMTP servers for our project's need.
Thanks to Erik's git school and tool support, I learned to use git to commit my code to our repository.

In Sprint 2, I wrote the first version of our SMTP-frontend server,
which enables Email clients to communicate with the backend to register or update users.
The parser of SMTP server was later being refactored by Andre to support both SMTP and XMPP frontend at the same time.
Besides, with the help of JD and Sukumar, I've also done our code review checklist.
And thanks to Stephan, I learned the benefits of writing testing code.

During Sprint 3, I worked with Rahim on extending parser and controller to support more user features.
In addition, I extended the parser to support Diplomacy game orders,
which interprets the player orders from plaintext to our rule engine compatible format.
Great thanks to Sukumar's Unix school,
it made life much easier to work with Linux since I've never truly used it before.

Sprint 4, I extended web-interface and backend to support in-game messaging.
I've also done the operator web-interface for inspecting DB status.
With some help from Sukumar, I've polished the web-interface a bit.

In Sprint 5, I created the operator-interface for inspecting details of a game.
Also, I worked with Dilshod to make the game map usable on our web-interface.
\section{Tiina Loukusa}
In the first sprint, we were supposed to find out what tools and existing
open source software to use, I had a look at the web servers Chicago Boss and
Mochiweb, the database CouchDB and a bit at Zotonic along with Stephan.

In sprint 2 and after the first architecture was done, we found that we
needed to look into it in more detail. I joined the architecture/design team
later on to work on finding out what types of Erlang behaviours would be
suitable where and what the supervision should look like. Other than
architecture, I also worked on connecting a user through the web interface to
the backend.

In sprint 3 I was mainly working on the backend, and more specifically things
related to the game, games are started when they are created and processing of
game changes, so that the games progress properly.

Sprint 4 and 5 involved adding some operator and moderator functionality, such
as getting an overview of the state of the running backends and communication
between operators/moderators and users. I was also working a little with Sukumar
and Andre on the load testing, mostly figuring out what to test, but then we
noticed that three people are too many for that and I continued working on other
tasks.
As fault tolerance was a part of sprint 4, I made sure that games were restarted
properly, with the help of the necromancer which Stephan had implemented, and
thanks to JD who was working with fault tolerance testing this could be tested
properly.
\section{Erik Timan}
I wanted this project to have good tool support so I was elected to be the
system administrator for the team. I was very busy with administrative tasks in
the beginning such as installing the needed software on our servers. The team
opted to use Redmine for issue tracking and planning, Gerrit for code review and
Buildbot for continuous integration. It took me a while to get everything up and
running and I needed to hack some of the tools to support our workflow better. I
also held schools on git and Redmine which took me a while to prepare.

I started working on the actual codebase during sprint 2. I took charge of
creating scripts for building and testing our system. Since we needed to
integrate code from external projects into our product and many of them were
quite painful to build, this was not as easy as we initially thought. By the end
of the sprint, most things worked and we could create releases of our system.

Initially in sprint 3 I worked with the poster that we would present at the
Erlang User Conference. Tiina and I worked together on first draft of the
poster. We got lots of feedback on our poster drafts and I spent quite some time
improving it. Later in the sprint I worked on reducing the build time for our
product since the long build times was making development slower. I also worked
on integration tests, game orders and various build improvements during this
sprint.

For me, the fourth sprint was mostly about making our releases actually work,
system configuration and fault tolerance testing. I created a proper staging
environment using the configuration manager Puppet. This allowed us to have
several light-weight virtual machines (containers) for fault tolerance testing
in a very easy and automated way. I then worked with Jan Daniel on fault
tolerance testing. We reached a point were we needed an easy way to configure a
cluster of machines running various parts of our system. We created the cluster
and system managers as the cure to those problems. By the end of the sprint we
could actually deploy our system in a distributed fashion very easily.

Since sprint 5 was mostly about wrapping up the product, most of my time was
spent on polish and fixes. I added proper logging to the system and rolled our
different releases into a single one. I spent time on getting our integration
tests to actually use the cluster/system managers to control the system since
this got rid of lots of false positives that we got on Buildbot. I spent several
days on bug fixing our build-test-release cycle since we were hitting all kinds
of weird bugs during testing. I also spent a few days on trying to fix problems
found by Dialyzer in our codebase as part of the general clean-up.
\section{Sukumar Yethadka}
Building large scale internet systems and its challenges are very interesting to me, which is why, this project along with its requirement of ``Erlang for everything" was an ideal fit.

During the initial survey sprint, I looked at various open source applications (Yaws, ejabberd, Chicago boss) and tested to check if it worked with the kind of usage we had in mind. I created slides for the Unix school with help from Andre. I also helped create the coding guidelines and code review checklist.

Sprint 2 mostly involved working with the database. I did some basic read up on Riak, learing how to use it efficiently. Then, I created the data model for the system, updating it as per team feedback. I tested the data model with basho bench thus making sure that Riak was a good starting point as the database. I also provided feedback and suggested improvements to the initial version of the architecture.

During sprint 3, I worked on the web frontend. After holding the Unix school, I refactored the web frontend making it more modular, consistent and eaisily extendible. It could have been better if we had used a traditional MVC framework, but we decided to keep it simple making it javascript heavy.

I worked on Riak search and load testing during sprint 4. I setup Riak search and setup the search schema for the buckets. I also got it to work with the web frontend. During the later half of the sprint, I worked on defining and creating load tests along with Tiina and also created good visuals for the load test results, using a open source project - highcharts.

With most of the core features completed, I worked on adding the less important features, fixing bugs, cleaning code and fixing the documentation during sprint 5.

Overall, this project was a unique and memorable experience for me and is definitely a recommendation for future students.

\chapter{Survey}
After a brief survey in the early stages of the project, we chose a few projects to look at in more detail, to be able to make a fair decision on what might be suitable for the Diplomacy server. As a reminder, all the below projects are based on Erlang.

\section{Web Frameworks}
\subsection{Zotonic}
Zotonic\cite{zotonic} is a CMS based on Erlang. It has a powerful control interface, has
quite a number of modules available such as authentication and chat and it
achieves modularity by following OTP-principles. Zotonic has support for
websockets, and when websockets are not supported by the browser, it will use
Comet instead. Zotonic has been insprired by Nitrogen and it can only be run
on a MochiWeb server.

\subsection{Erlang Web}
Erlang Web\cite{erlangweb} is quite simplistic, it has support for multiple web servers and
distribution. It does not have any extras like a chat nor does it have support
for websockets. Erlang Web can be run on INETS and YAWS web servers.

\subsection{Nitrogen}
Nitrogen\cite{nitrogen} uses an event-driven model and offers hot code swapping, stability
and scalability. It includes a simple, yet powerful, template system and is
well documented which is important for us as developers. Nitrogen can run on
several web servers; MochiWeb, YAWS and INETS.

\subsection{Chicago Boss}
Chicago Boss\cite{chicagoboss} is a new web framework, which has not yet reached
a stable state. Even though it hasn't reached 1.0, it still offers some nice
features, as it supports multiple databases, hot code swapping and e-mail among
other things. It is well documented but it does not support websockets nor
distributed systems.

\subsection{Results and discussion}
When we tried to decide on what web framework to use, we wanted simplicity, as
we had already decided on not to focus on the look and feel and we didn't want
to spend a lot of time on learning a specific web framework.
The project required the use of websockets and if the framework didn't
provide that up front, we would need to implement it ourselves.\\

Chicago Boss was too immature to be an option, as we want something stable that
we won't need to patch up too much and Erlang Web was very basic and didn't
provide many features that we could use, compared to the other ones.

The only web framework that had support for websockets was Zotonic, but it was
quite complex to learn to use it, and it didn't provide the kind of simplicity
we were looking for. We came to the conclusion that it would be of more use to
us to use a web framework that was easy to use and implement websocket support,
rather than learning how to create new modules for Zotonic.\\

We initially decided to use Nitrogen, because we found that it was one of the
more mature and well used web frameworks out of those we looked at. It could
work with both of the web servers we were choosing among, it was easy to use and
it provided some nice and useful features. It didn't have websocket support but
we thought we would be able to implement that.

Unfortunately, we came to the conclusion that implementing websocket support
into Nitrogen is a project on its own, and we decided to not use a web
framework at all. We ended up using only Javascript, which was sufficient for
our use.

\section{Web Servers}
\subsection{MochiWeb}
Mochiweb\cite{mochiweb} claims to provide a lightweight and lightning fast webserver.
Several sources say that it has been used by Facebook for their chat\cite{fb_chat}\cite{fb_pres},
due to these properties. It is easy to set up and get running. It was really
hard to find any documentation, because there is almost no documentation online,
only the API that can be generated by edocs which in retrospective should be
quite intuitive. A big drawback for this project was that it doesn't have
support for websockets.

\subsection{Yaws}
Yaws\cite{yaws} is a high performance web server, which has a large and active
community and is thus regularly updated. It can be run in two different modes;
as a standalone application or as an embedded application. Their webpage
provides a large number of example use cases and it is well documented, which
might be a reason to its large user base. Something that really appealed to us
was the fact that it actually had websocket support!

\subsection{Results and discussion}
Both contenders were good webservers and we chose to look into these two more
closely because Nitrogen, which was the web framework we chose to use,
supported both. We had to choose one, and the lack of documentation and support
for websockets in MochiWeb made us choose Yaws. Websocket support was definitely
the deciding factor.\\

As the websocket protocol kept changing under the course of the project, we were
lucky enough to have JD in the team, who found websockets to be very interesting
and cool. He updated the websocket implementation in Yaws, and these changes for
Websocket RFC 6455 are now included in the release of Yaws 1.92.\\


Yaws seems to have been a fairly good choise, but during the EUC we became
aware of another web server, Cowboy\cite{cowboy_pres}, which in retrospective,
probably would have been an even better decision as the developer for Cowboy is
very keen on having the latest websocket version at all times. Why we didn't
even consider it an option was because it was very new and it had just entered
early beta when we did the survey when we had more mature options to choose from.

\section{SMTP Servers}
\subsection{Erlmail}
Erlmail is a complete email solution written in Erlang. It contains OTP
compliant SMTP, IMAP and POP clients and servers. According to our observation
of its source code, it didn't support encryption.

\subsection{gen\_smtp}
Gen\_smtp is written in OTP style, it inlcudes only SMTP client and server,
which means it doesn't involve any email retrieval mechanism like IMAP or POP,
and this makes it look simple. Besides, it supports SMTP SSL/TLS-encryption.

\subsection{erlang-smtp}
Erlang-smtp contains client and server for SMTP and POP3.
According to its author, it does not yet support encryption.

\subsection{Results and discussion}
Considering the fact that we only need a simple server to send and receive
emails, we didn't need any feature other than SMTP. Therefore,
our architecture team voted for gen\_smtp for its simplicity.

\section{XMPP}
\subsection{ejabberd server}
ejabberd is a distributed Jabber/XMPP instant messaging server. It has modular architecture, web administrator interface and simple configuration. It supports the addition of Erlang modules using hooks which can be added allowing it to control the server programtically. It also supports more advanced features such as components and server to server (S2S) protocol.

\subsection{EXMPP client}
EXMPP is a XMPP client with SSL support. It provides a lot of functionality to deal with XML and supports several XML parsers. However, its documentation is sparse.

\subsection{Results and discussion}
We didn't really have any options here and we had to go with ejabberd as our XMPP server.

We did have choices as to how we connect to the XMPP server from our application - via ejabberd module, component or the EXMPP client. We ended up using the ejabberd module for its tight integration and simplicity.

However, we did use EXMPP later in the project for integration testing the IM server.

\section{Databases}
\subsection{Mnesia}
Mnesia is a distributed relational database designed for telecom systems and is a part of Erlang/OTP distribution. It is a well documented, fault tolerant, ACID\cite{ACID} compliant database that supports dynamic reconfiguration as well as transactions. However, it has a storage limit of 4 gigabytes and has a learning curve of its own custom query language.

\subsection{Riak}
Riak is a distributed key value database based on CAP theorem\cite{cap_theorem} and Amazon's dynamo paper\cite{dynamo}. It provides features such as RESTful interface, protocol buffers interface, ability to tune CAP values at the bucket level, map reduce queries, link walking, secondary indicies and search. All the data is replicated across the nodes based on the configuration without the usage of a master node. It is fault tolerant and built with horizontal scaling in mind. Riak, by design, is eventually consistent.

\subsection{CouchDB}
CouchDB is a distributed document oriented database and is quite similar to Riak in terms of its feature set. Its differentiating factors are that the document is stored as a JSON object, it is ACID compliant, uses Multi-Version Concurrency Control (MVCC) and has indexed views providing fast queries. Also unlike Riak, each node of CouchDB stores the entire dataset and it has the concept of a master node.

\subsection{Results and discussion}
The initial thought we had when starting off with the project is that in order to make our system scalable and fault tolerant, we need to reduce the state of our backend as much as possbile. This resulted in a database driven architecture, making our choices more specific.

While Mnesia was a good option, it was not linearly scalable due to its transactions. In order to keep the data consistent, Mnesia uses transactions that lock up the data until all the copies in all the nodes are updated.

CouchDB was also a good option, but because it stored all the data in all the nodes and had a single point of failure - the master, we couldn't use it.

Riak, with all its features and documentation, seemed like a perfect fit for us. The main selling point for us was its advertised linear scaling and fault tolerance. Basho releasing a stable 1.0 version during the survey helped as well.

\renewcommand\bibname{References}
\bibliographystyle{unsrtnat}
\bibliography{course_rep}
\todo{add bibtex}

\end{document}
